{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digit_detect.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoSTCnssuptA"
      },
      "source": [
        "#### Imports for main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H58vsaspuNho"
      },
      "source": [
        "from torchvision import torch, datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as fnc\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ-UyXFouzxQ"
      },
      "source": [
        "#### Imports for model class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58I_gYmuu3IL"
      },
      "source": [
        "import numpy as np\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRicGKhCvItz"
      },
      "source": [
        "#### Imports for image manipulation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qNo15pnvNsR"
      },
      "source": [
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIzx6ZHA4hnv"
      },
      "source": [
        "#### Mounting your Google Drive\n",
        "\n",
        "**Note:** You will need to make a folder called \"Colab Notebooks\" in your Google Drive. Under this folder, make a folder called \"MNIST_ocr\". Store the image(s) to be analyzed in this folder under a folder called \"test_images\". Make another folder under MNIST_ocr called \"bnw_images\".\n",
        "\n",
        "Alternatively, you can find pre-made folders at <a href=\"https://github.com/black-tul1p/digit-ocr\">my GitHub repo</a>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0nZf2ZO4IwA",
        "outputId": "94eec5df-145c-4968-f071-2266857bf5cc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ai5PG-buTBa"
      },
      "source": [
        "#### Global variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89eJm4kquXXm"
      },
      "source": [
        "image_size = 28*28\n",
        "num_classes = 10\n",
        "batch = 100\n",
        "img_num = 3\n",
        "debug = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGwn--a3u61v"
      },
      "source": [
        "#### MNIST model class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnpjVqOnu84O"
      },
      "source": [
        "## Class that defines the LR model\n",
        "class MNIST_Model(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.linear=nn.Linear(image_size, num_classes)\n",
        "\n",
        "\tdef forward(self, image):\n",
        "\t\timage = image.reshape(-1, 784)\n",
        "\t\toutput = self.linear(image)\n",
        "\t\treturn output\n",
        "\n",
        "\tdef training_step(self, batch):\n",
        "\t\timages, labels = batch\n",
        "\t\toutput = self(images)\n",
        "\t\tloss = fnc.cross_entropy(output, labels)\n",
        "\t\treturn loss\n",
        "\t\n",
        "\tdef validation_step(self, batch):\n",
        "\t\timages, labels=batch\n",
        "\t\toutput = self(images)\n",
        "\t\tloss = fnc.cross_entropy(output, labels)\n",
        "\t\tacc = get_accuracy(output, labels)\n",
        "\t\treturn {'val_loss': loss, 'val_acc': acc}\n",
        "\t\n",
        "\tdef validation_epoch_end(self, output):\n",
        "\t\tbatch_losses=[x['val_loss'] for x in output]\n",
        "\t\tepoch_loss=torch.stack(batch_losses).mean()\n",
        "\t\tbatch_accs=[x['val_acc'] for x in output]\n",
        "\t\tepoch_acc=torch.stack(batch_accs).mean()\n",
        "\t\treturn {'val_loss':epoch_loss.item(), 'val_acc':epoch_acc.item()}\n",
        "\t\n",
        "\tdef epoch_end(self, epoch, result):\n",
        "\t  print(\"Epoch [{}], val_loss={:.4f}, val_acc={:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVqBuj9tu_Tp"
      },
      "source": [
        "#### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjJDC9ZPvBTW"
      },
      "source": [
        "# Calculate gradient values using Stochastic Gradient Descent\n",
        "def get_gradient(epochs, model, lr, train_loader, test_loader):\n",
        "\toptimizer = torch.optim.SGD(model.parameters(), lr)\n",
        "\tfor epoch in tqdm(range(epochs), desc='Training progress'):\n",
        "\t\tfor batch in train_loader:\n",
        "\t\t\tloss = model.training_step(batch)\n",
        "\t\t\tloss.backward()\n",
        "\t\t\toptimizer.step()\n",
        "\t\t\toptimizer.zero_grad()\n",
        "\t\t# Validation of predictions for epoch\n",
        "\t\tresult = compare(model, test_loader)\n",
        "\t\tif debug == True:\n",
        "\t\t\tmodel.epoch_end(epoch, result)\n",
        "\n",
        "# Get % accuracy of predictions\n",
        "def get_accuracy(output, labels):\n",
        "\t_, predictions = torch.max(output, dim=1)\n",
        "\treturn torch.tensor(torch.sum(predictions == labels).item()/len(predictions))\n",
        "\n",
        "# Validates predictions\n",
        "def compare(model, test_loader):\n",
        "\tout=[model.validation_step(batch) for batch in test_loader]\n",
        "\treturn model.validation_epoch_end(out)\n",
        "\n",
        "# Returns prediction for given image\n",
        "def predict(image, model):\n",
        "\txb=image.unsqueeze(0)\n",
        "\tyb=model(xb)\n",
        "\t_, preds=torch.max(yb, dim=1)\n",
        "\treturn preds[0].item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc2E2boMvSwK"
      },
      "source": [
        "#### Image manipulation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQbzNK6LvVaz"
      },
      "source": [
        "def convert_bnw(in_path, out_path):\n",
        "\trgb_image = Image.open(in_path)\n",
        "\tbnw_image = rgb_image.convert('L')\n",
        "\tbnw_image.save(out_path)\n",
        "\n",
        "def resize_img(img_path):\n",
        "\tinput_im = cv2.imread(img_path)\n",
        "\tinput_im = cv2.resize(input_im, (28, 28))\n",
        "\tcv2.imshow(\"image_converted\", input_im)\n",
        "\tcv2.waitKey(0)\n",
        "\tcv2.destroyAllWindows()\n",
        "\treturn input_im\n",
        "\n",
        "def to_float_tensor(np_array):\n",
        "\treturn torch.from_numpy(np_array).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X6m7irCuZH6"
      },
      "source": [
        "#### Main function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHuIKP53ubUC"
      },
      "source": [
        "def main():\n",
        "\tchoice = input(\"Train the model? (Y/N): \").lower()\n",
        "\tif choice == \"y\":\n",
        "\t\tnum_epochs = int(input(\"Enter number of training Epochs: \"))\n",
        "\n",
        "\timage_name = input(\"Enter image name (under /test_images/): \")\n",
        "\tif image_name == \"\":\n",
        "\t\tprint(\"\\nNo image specified. Defaulting to image_{}.jpg...\\n\".format(img_num))\n",
        "\n",
        "\t# Get MNIST training data\n",
        "\tmnist_train = datasets.MNIST(root=\"./gdrive/MyDrive/Colab Notebooks/MNIST_ocr/datasets\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "\tmnist_test = datasets.MNIST(root=\"./gdrive/MyDrive/Colab Notebooks/MNIST_ocr/datasets\", train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "\t# Load and shuffle dataset\n",
        "\ttrain_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch, shuffle=True)\n",
        "\ttest_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch, shuffle=False)\n",
        "\n",
        "\t# Define model\n",
        "\tmodel = MNIST_Model()\n",
        "\tmodel.linear\n",
        "\tfor images, labels in train_loader:\n",
        "\t\tout = model(images)\n",
        "\t\tbreak\n",
        "\n",
        "\t# Get probabilities using softmax function \n",
        "\tprob = fnc.softmax(out, dim=1)\n",
        "\n",
        "\t# saving the model\n",
        "\tif choice == \"y\":\n",
        "\t\tget_gradient(num_epochs, model, 0.4, train_loader, test_loader)\n",
        "\t\ttorch.save(model.state_dict(), './gdrive/MyDrive/Colab Notebooks/MNIST_ocr/mnist-digit-ocr.pth')\n",
        "\n",
        "\t# Read image and convert to greyscale\n",
        "\tif image_name == \"\":\n",
        "\t\tin_path =  os.path.join(\".\", \"gdrive\", \"MyDrive\", \"Colab Notebooks\", \"MNIST_ocr\", \"test_images\", \"image_\"+str(img_num)+\".png\")\n",
        "\t\tout_path = os.path.join(\".\", \"gdrive\", \"MyDrive\", \"Colab Notebooks\", \"MNIST_ocr\", \"bnw_images\", \"outfile\"+str(img_num)+\".png\")\n",
        "\telse:\n",
        "\t\tin_path =  os.path.join(\".\", \"gdrive\", \"MyDrive\", \"Colab Notebooks\", \"MNIST_ocr\", \"test_images\", image_name)\n",
        "\t\tout_path = os.path.join(\".\", \"gdrive\", \"MyDrive\", \"Colab Notebooks\", \"MNIST_ocr\", \"bnw_images\", image_name)\n",
        "\tconvert_bnw(in_path, out_path)\n",
        "\tplt.imshow(cv2.imread(out_path))\n",
        "\n",
        "\t# Resize and convert image to Tensor for analysis\n",
        "\tinput_im = resize_img(out_path)\n",
        "\tinput_im = to_float_tensor(input_im)\n",
        "\n",
        "\t# Load existing model if requested\n",
        "\tif choice != \"y\":\n",
        "\t\tmodel_new = MNIST_Model()\n",
        "\t\tmodel_new.load_state_dict(torch.load('./gdrive/MyDrive/Colab Notebooks/MNIST_ocr/mnist-digit-ocr.pth'))\n",
        "\t\t# print('Label:', label, ', Predicted:', predict(input_im, model_new))\n",
        "\t\tprint('Predicted:', predict(input_im, model_new))\n",
        "\telse:\n",
        "\t\t# print('Label:', label, ', Predicted:', predict(input_im, model))\n",
        "\t\tprint('Predicted:', predict(input_im, model))\n",
        "\t\t# input(\"Save? (ctrl-C to save)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FTVVRczuhQN"
      },
      "source": [
        "#### Calling main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "YeFZBbGZuja3",
        "outputId": "f521fabf-4c22-48d7-94cb-15cd4b9323c1"
      },
      "source": [
        "if __name__==\"__main__\":\n",
        "\tmain()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train the model? (Y/N): n\n",
            "Enter image name (under test_images/): \n",
            "\n",
            "No image specified. Defaulting to image_3.jpg...\n",
            "\n",
            "\n",
            "Analyzed image:\n",
            "\n",
            "Predicted: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}